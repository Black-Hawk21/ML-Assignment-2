{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IOOQ5Lz-JioQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# import pandas_datareader as web\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnepZsFhJxN2"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vt_Ols0J0W1"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGD1Ch7JybV",
        "outputId": "979e3479-2582-43ef-dc2b-0e353e69ca8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trip_id\n",
            "country\n",
            "num_males\n",
            "mainland_stay_nights\n",
            "island_stay_nights\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Load data\n",
        "trainData = pd.read_csv(\"train.csv\")\n",
        "testData  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# FUNCTION to clean categorical text\n",
        "# -----------------------------------------\n",
        "def clean_text_columns(df):\n",
        "    cat_cols = df.select_dtypes(include=['object']).columns\n",
        "    punct_table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    for col in cat_cols:\n",
        "        if col == 'trip_id':\n",
        "            continue\n",
        "        df[col] = df[col].apply(\n",
        "            lambda x:\n",
        "                x.translate(punct_table)\n",
        "                 .replace(\" \", \"_\")\n",
        "                 .lower()\n",
        "                 .strip()\n",
        "            if isinstance(x, str) else x   # KEEP NaN AS IT IS\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# -----------------------------------------\n",
        "# Apply to both train & test\n",
        "# -----------------------------------------\n",
        "trainData = clean_text_columns(trainData)\n",
        "testData  = clean_text_columns(testData)\n",
        "combined = pd.concat([trainData, testData], axis=0)\n",
        "for col in testData.columns:\n",
        "    if (combined[col].nunique() != trainData[col].nunique()):\n",
        "        print(col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12654 entries, 0 to 12653\n",
            "Data columns (total 25 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   trip_id                      12654 non-null  object \n",
            " 1   country                      12424 non-null  object \n",
            " 2   age_group                    12646 non-null  object \n",
            " 3   travel_companions            11917 non-null  object \n",
            " 4   num_females                  12652 non-null  float64\n",
            " 5   num_males                    12650 non-null  float64\n",
            " 6   main_activity                12526 non-null  object \n",
            " 7   visit_purpose                12654 non-null  object \n",
            " 8   is_first_visit               12555 non-null  object \n",
            " 9   mainland_stay_nights         12654 non-null  int64  \n",
            " 10  island_stay_nights           12654 non-null  int64  \n",
            " 11  tour_type                    12654 non-null  object \n",
            " 12  intl_transport_included      12507 non-null  object \n",
            " 13  info_source                  12654 non-null  object \n",
            " 14  accomodation_included        12511 non-null  object \n",
            " 15  food_included                12483 non-null  object \n",
            " 16  domestic_transport_included  12654 non-null  object \n",
            " 17  sightseeing_included         12654 non-null  object \n",
            " 18  guide_included               12654 non-null  object \n",
            " 19  insurance_included           12418 non-null  object \n",
            " 20  days_booked_before_trip      11101 non-null  object \n",
            " 21  arrival_weather              9251 non-null   object \n",
            " 22  total_trip_days              12252 non-null  object \n",
            " 23  has_special_requirements     4537 non-null   object \n",
            " 24  spend_category               12620 non-null  float64\n",
            "dtypes: float64(3), int64(2), object(20)\n",
            "memory usage: 2.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(trainData.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FPnIbahLp5D"
      },
      "source": [
        "Removing Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MYdNUklLsT4",
        "outputId": "7b43a065-ea52-48c0-ce14-dd1a5a06d017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "days_booked_before_trip\n",
            "arrival_weather\n",
            "has_special_requirements\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def drop_rows_for_low_nan_columns(df, threshold=50):\n",
        "    for col in df.columns:\n",
        "        nan_count = df[col].isna().sum()\n",
        "\n",
        "        # If column has fewer than threshold NaNs â†’ drop those rows\n",
        "        if nan_count < threshold and nan_count > 0:\n",
        "            df = df.dropna(subset=[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply to both train and test\n",
        "trainData = drop_rows_for_low_nan_columns(trainData, threshold=50)\n",
        "\n",
        "def removeNullValues(data):\n",
        "    replace_numeric_null = {}\n",
        "    replace_cat_null = {}\n",
        "    # Identify features\n",
        "    numeric_features = [c for c in data.select_dtypes(include=['float64','int64']).columns \n",
        "                    if c != \"spend_category\"]\n",
        "\n",
        "    categorical_features = [c for c in data.select_dtypes(exclude=['float64','int64']).columns\n",
        "                    if c != \"spend_category\"]\n",
        "    for col in numeric_features:\n",
        "        replace_numeric_null[col] = data[col].median()\n",
        "    for col in categorical_features:\n",
        "        count = data[col].isna().sum()\n",
        "        if count <= 1000:\n",
        "            replace_cat_null[col] = data[col].mode()[0]\n",
        "        else :\n",
        "            replace_cat_null[col] = 'none'\n",
        "            print(col)\n",
        "\n",
        "    return replace_cat_null, replace_numeric_null\n",
        "\n",
        "def apply_null_remove(data, cat, num):\n",
        "    numeric_features = [c for c in data.select_dtypes(include=['float64','int64']).columns \n",
        "                    if c != \"spend_category\"]\n",
        "\n",
        "    categorical_features = [c for c in data.select_dtypes(exclude=['float64','int64']).columns\n",
        "                    if c != \"spend_category\"]\n",
        "    for col in numeric_features:\n",
        "        data[col] = data[col].fillna(num[col])\n",
        "    for col in categorical_features:\n",
        "        data[col] = data[col].fillna(cat[col])\n",
        "\n",
        "cat, num = removeNullValues(trainData)\n",
        "\n",
        "apply_null_remove(trainData, cat, num)\n",
        "apply_null_remove(testData, cat, num)\n",
        "\n",
        "country_freq = trainData['country'].value_counts(normalize=True)\n",
        "\n",
        "# trainData['country'] = trainData['country'].map(country_freq)\n",
        "# testData['country'] = testData['country'].map(country_freq).fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5lAgzzQ24h"
      },
      "source": [
        "Remove the ID column from train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xK5TiSoBQ5vF"
      },
      "outputs": [],
      "source": [
        "trainData = trainData.drop('trip_id', axis=1)\n",
        "testId = testData['trip_id']\n",
        "testData = testData.drop('trip_id', axis=1)\n",
        "\n",
        "trainData['num_females'] = trainData['num_females'].astype(int)\n",
        "testData['num_females'] = testData['num_females'].astype(int)\n",
        "trainData['num_males'] = trainData['num_males'].astype(int)\n",
        "testData['num_males'] = testData['num_males'].astype(int)\n",
        "\n",
        "trainData['number_of_visitors'] = trainData['num_males'] + trainData['num_females']\n",
        "testData['number_of_visitors'] = testData['num_males'] + testData['num_females']\n",
        "\n",
        "trainData = trainData.drop(columns=['num_males', 'num_females'])\n",
        "testData = testData.drop(columns=['num_males', 'num_females'])\n",
        "\n",
        "def encode_stay_nights(series):\n",
        "    return (\n",
        "        series\n",
        "        .apply(lambda x:\n",
        "               0 if x <= 10 else\n",
        "               1 if x <= 50 else\n",
        "               2 if x <= 100 else\n",
        "               3)\n",
        "    )\n",
        "\n",
        "# Mainland stay nights encoding\n",
        "trainData['mainland_stay_nights'] = encode_stay_nights(trainData['mainland_stay_nights'])\n",
        "testData['mainland_stay_nights']  = encode_stay_nights(testData['mainland_stay_nights'])\n",
        "\n",
        "# Island stay nights encoding\n",
        "trainData['island_stay_nights'] = encode_stay_nights(trainData['island_stay_nights'])\n",
        "testData['island_stay_nights']  = encode_stay_nights(testData['island_stay_nights'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 12606 entries, 0 to 12653\n",
            "Data columns (total 23 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   country                      12606 non-null  object \n",
            " 1   age_group                    12606 non-null  object \n",
            " 2   travel_companions            12606 non-null  object \n",
            " 3   main_activity                12606 non-null  object \n",
            " 4   visit_purpose                12606 non-null  object \n",
            " 5   is_first_visit               12606 non-null  object \n",
            " 6   mainland_stay_nights         12606 non-null  int64  \n",
            " 7   island_stay_nights           12606 non-null  int64  \n",
            " 8   tour_type                    12606 non-null  object \n",
            " 9   intl_transport_included      12606 non-null  object \n",
            " 10  info_source                  12606 non-null  object \n",
            " 11  accomodation_included        12606 non-null  object \n",
            " 12  food_included                12606 non-null  object \n",
            " 13  domestic_transport_included  12606 non-null  object \n",
            " 14  sightseeing_included         12606 non-null  object \n",
            " 15  guide_included               12606 non-null  object \n",
            " 16  insurance_included           12606 non-null  object \n",
            " 17  days_booked_before_trip      12606 non-null  object \n",
            " 18  arrival_weather              12606 non-null  object \n",
            " 19  total_trip_days              12606 non-null  object \n",
            " 20  has_special_requirements     12606 non-null  object \n",
            " 21  spend_category               12606 non-null  float64\n",
            " 22  number_of_visitors           12606 non-null  int64  \n",
            "dtypes: float64(1), int64(3), object(19)\n",
            "memory usage: 2.3+ MB\n",
            "None\n",
            "[0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "print(trainData.info())\n",
        "print(trainData['mainland_stay_nights'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efr0fNY4RgPx"
      },
      "source": [
        "More EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sqyi27D_Rhhx",
        "outputId": "3a331c76-3105-483c-b544-82b3b835c6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 12606 entries, 0 to 12653\n",
            "Data columns (total 20 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   country                   12606 non-null  object \n",
            " 1   age_group                 12606 non-null  object \n",
            " 2   travel_companions         12606 non-null  object \n",
            " 3   main_activity             12606 non-null  object \n",
            " 4   visit_purpose             12606 non-null  object \n",
            " 5   is_first_visit            12606 non-null  object \n",
            " 6   mainland_stay_nights      12606 non-null  int64  \n",
            " 7   island_stay_nights        12606 non-null  int64  \n",
            " 8   tour_type                 12606 non-null  object \n",
            " 9   intl_transport_included   12606 non-null  object \n",
            " 10  info_source               12606 non-null  object \n",
            " 11  sightseeing_included      12606 non-null  object \n",
            " 12  guide_included            12606 non-null  object \n",
            " 13  insurance_included        12606 non-null  object \n",
            " 14  days_booked_before_trip   12606 non-null  object \n",
            " 15  arrival_weather           12606 non-null  object \n",
            " 16  total_trip_days           12606 non-null  object \n",
            " 17  has_special_requirements  12606 non-null  object \n",
            " 18  spend_category            12606 non-null  float64\n",
            " 19  number_of_visitors        12606 non-null  int64  \n",
            "dtypes: float64(1), int64(3), object(16)\n",
            "memory usage: 2.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "numeric_features = list(trainData.iloc[:, :-1].select_dtypes(include=['float64', 'int64']).columns)\n",
        "categorical_features = list(trainData.select_dtypes(exclude=['float64', 'int64']).columns)\n",
        "\n",
        "# target = 'spend_category'\n",
        "\n",
        "# for col in categorical_features:\n",
        "#     plt.figure(figsize=(8, 4))\n",
        "\n",
        "#     sns.countplot(\n",
        "#         data=trainData,\n",
        "#         x=col,\n",
        "#         hue=target\n",
        "#     )\n",
        "\n",
        "#     plt.title(f\"{col} vs {target} (countplot)\")\n",
        "#     plt.xticks(rotation=45)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "import numpy as np\n",
        "\n",
        "def cramers_v(x, y):\n",
        "    confusion_matrix = pd.crosstab(x, y)\n",
        "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
        "    n = confusion_matrix.sum().sum()\n",
        "    r, k = confusion_matrix.shape\n",
        "    return np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
        "\n",
        "# for col1 in categorical_features:\n",
        "#   for col2 in categorical_features:\n",
        "#     if col1 != col2:\n",
        "#       if cramers_v(trainData[col1], trainData[col2]) > 0.7:\n",
        "#         print(col1, \" \" , col2, \" \", cramers_v(trainData[col1], trainData[col2]))\n",
        "\n",
        "trainData = trainData.drop(columns=['accomodation_included',\n",
        "                                    'food_included',\n",
        "                                    'domestic_transport_included'])\n",
        "testData = testData.drop(columns=['accomodation_included',\n",
        "                                    'food_included',\n",
        "                                    'domestic_transport_included'])\n",
        "print(trainData.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tkvOqMBWVF-"
      },
      "source": [
        "Encode Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glm8KnzaWXr1",
        "outputId": "d686bfa1-828e-488a-92d6-8925136b1de2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Define the new binary columns\n",
        "def encode_travel(df):\n",
        "    df['with_children'] = df['travel_companions'].isin(\n",
        "        ['With Spouse and Children', 'With Children']\n",
        "    ).astype(int)\n",
        "\n",
        "    df['with_spouse'] = df['travel_companions'].isin(\n",
        "        ['With Spouse and Children', 'With Spouse']\n",
        "    ).astype(int)\n",
        "\n",
        "    df['with_friends'] = df['travel_companions'].isin(\n",
        "        ['With Other Friends/Relatives']\n",
        "    ).astype(int)\n",
        "\n",
        "# Apply encoding\n",
        "encode_travel(trainData)\n",
        "encode_travel(testData)\n",
        "\n",
        "# Drop the original column\n",
        "trainData = trainData.drop(columns=['travel_companions'])\n",
        "testData  = testData.drop(columns=['travel_companions'])\n",
        "\n",
        "trainData['visit_purpose'] = trainData['visit_purpose'].replace('Widlife Tourism', 'Wildlife Tourism')\n",
        "testData['visit_purpose'] = testData['visit_purpose'].replace('Widlife Tourism', 'Wildlife Tourism')\n",
        "trainData['main_activity'] = trainData['main_activity'].replace('Widlife Tourism', 'Wildlife Tourism')\n",
        "testData['main_activity'] = testData['main_activity'].replace('Widlife Tourism', 'Wildlife Tourism')\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Clean whitespace in categorical columns\n",
        "# ---------------------------------------------------------\n",
        "for col in ['age_group', 'days_booked_before_trip', 'total_trip_days']:\n",
        "    trainData[col] = trainData[col].astype(str).str.strip()\n",
        "    testData[col]  = testData[col].astype(str).str.strip()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Extract categorical columns\n",
        "# ---------------------------------------------------------\n",
        "cat_cols = trainData.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Remove manually-encoded ordinal columns\n",
        "protected = ['age_group', 'days_booked_before_trip', 'total_trip_days']\n",
        "cat_cols = [c for c in cat_cols if c not in protected]\n",
        "\n",
        "# (note: travel_companions was removed above)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Process categorical columns\n",
        "# ---------------------------------------------------------\n",
        "ohe_cols = []\n",
        "for col in cat_cols:\n",
        "    if trainData[col].nunique() <= 2 and testData[col].nunique() <= 2:\n",
        "        le = LabelEncoder()\n",
        "        all_vals = pd.concat([trainData[col], testData[col]], axis=0)\n",
        "        le.fit(all_vals)\n",
        "\n",
        "        trainData[col] = le.transform(trainData[col])\n",
        "        testData[col]  = le.transform(testData[col])\n",
        "    else:\n",
        "        ohe_cols.append(col)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. One-hot encode multi-category columns\n",
        "# ---------------------------------------------------------\n",
        "combined = pd.concat([trainData, testData], axis=0)\n",
        "combined = pd.get_dummies(combined, columns=ohe_cols, drop_first=False)\n",
        "\n",
        "# Split back\n",
        "trainData = combined.iloc[:len(trainData)].copy()\n",
        "testData  = combined.iloc[len(trainData):].copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Ordinal maps\n",
        "# ---------------------------------------------------------\n",
        "age_map = {\n",
        "    '<18': 0,\n",
        "    '18-24': 1,\n",
        "    '25-44': 2,\n",
        "    '45-64': 3,\n",
        "    '65+': 4,\n",
        "    'none': -1\n",
        "}\n",
        "\n",
        "days_map = {v:i for i,v in enumerate(['1-7','8-14','15-30','31-60','61-90','90+','none'])}\n",
        "trip_days_map = {v:i for i,v in enumerate(['1-6','7-14','15-30','30+','none'])}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Apply mapping (safe)\n",
        "# ---------------------------------------------------------\n",
        "for col, mapping in [\n",
        "    ('age_group', age_map),\n",
        "    ('days_booked_before_trip', days_map),\n",
        "    ('total_trip_days', trip_days_map)\n",
        "]:\n",
        "    trainData[col] = trainData[col].map(mapping).fillna(-1).astype(int)\n",
        "    testData[col]  = testData[col].map(mapping).fillna(-1).astype(int)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Done\n",
        "# ---------------------------------------------------------\n",
        "# print(trainData.info())\n",
        "# print(testData.info())\n",
        "# for col in trainData.columns:\n",
        "#     print(col, trainData[col].unique())\n",
        "# print(trainData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhH-GtGUaUwX"
      },
      "source": [
        "Split into X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FjKuxVeeaOpM"
      },
      "outputs": [],
      "source": [
        "X = trainData.drop(columns=['spend_category'])\n",
        "y = trainData['spend_category']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4czWV29aMzv"
      },
      "source": [
        "Scale featues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "k6sEZDvMaOWL"
      },
      "outputs": [],
      "source": [
        "if 'spend_category' in testData.columns:\n",
        "    testData = testData.drop(columns=['spend_category'])\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "test_scaled = scaler.transform(testData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USwa8HXzVzkp"
      },
      "source": [
        "Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0oTLlEaWGEA",
        "outputId": "08814fb7-3d2a-48a2-a981-19ea838befdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END .max_features=1.0, max_samples=0.6, n_estimators=20; total time=   2.1s\n",
            "[CV] END .max_features=1.0, max_samples=0.6, n_estimators=20; total time=   2.1s\n",
            "[CV] END .max_features=1.0, max_samples=0.6, n_estimators=20; total time=   2.1s\n",
            "[CV] END .max_features=1.0, max_samples=0.6, n_estimators=20; total time=   2.1s\n",
            "[CV] END .max_features=1.0, max_samples=0.6, n_estimators=20; total time=   2.1s\n",
            "\n",
            "Best Bagging Params:\n",
            "{'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 20}\n",
            "\n",
            "Best CV Accuracy: 0.7397268181219075\n",
            "\n",
            "Training Accuracy: 0.7486117721719816\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.85      0.84      6237\n",
            "         1.0       0.68      0.72      0.70      4907\n",
            "         2.0       0.66      0.38      0.49      1462\n",
            "\n",
            "    accuracy                           0.75     12606\n",
            "   macro avg       0.72      0.65      0.67     12606\n",
            "weighted avg       0.74      0.75      0.74     12606\n",
            "\n",
            "Saved: bagging_logistic_fixedLR_gridsearch.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Fixed logistic parameters (cleaned)\n",
        "# -------------------------\n",
        "best_lr_params = {\n",
        "    \"C\": 0.1,\n",
        "    \"penalty\": \"l2\",\n",
        "    \"solver\": \"lbfgs\",\n",
        "    \"max_iter\": 5000\n",
        "}\n",
        "\n",
        "base_lr = LogisticRegression(**best_lr_params)\n",
        "\n",
        "# -------------------------\n",
        "# Bagging classifier\n",
        "# -------------------------\n",
        "bag = BaggingClassifier(\n",
        "    estimator=base_lr,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Bagging parameter grid\n",
        "# -------------------------\n",
        "param_grid = {\n",
        "    \"n_estimators\": [20],\n",
        "    \"max_samples\": [0.6],\n",
        "    \"max_features\": [1.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=bag,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"\\nBest Bagging Params:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(\"\\nBest CV Accuracy:\", grid.best_score_)\n",
        "\n",
        "# -------------------------\n",
        "# Evaluate training performance\n",
        "# -------------------------\n",
        "best_bag = grid.best_estimator_\n",
        "\n",
        "train_pred = best_bag.predict(X_scaled)\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Test predictions\n",
        "# -------------------------\n",
        "test_pred = best_bag.predict(test_scaled)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"trip_id\": testId,\n",
        "    \"spend_category\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"bagging_logistic_fixedLR_gridsearch.csv\", index=False)\n",
        "print(\"Saved: bagging_logistic_fixedLR_gridsearch.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3E39W8-V7s6"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCaoaci7WGfV",
        "outputId": "e971193b-0805-4cd1-ec24-74f3d5f85d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  22.6s\n",
            "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  23.1s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  23.2s\n",
            "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  23.2s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  23.3s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  23.3s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  23.4s\n",
            "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  23.5s\n",
            "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  23.0s\n",
            "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  23.4s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  24.2s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  24.2s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  24.4s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  24.5s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  24.8s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  24.7s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  25.3s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  25.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  24.7s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  25.1s\n",
            "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=  35.6s\n",
            "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=  36.6s\n",
            "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=  36.9s\n",
            "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=  36.8s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  22.6s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  22.4s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  22.7s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  20.9s\n",
            "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  20.9s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=  21.4s\n",
            "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  21.3s\n",
            "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=  35.6s\n",
            "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  19.7s\n",
            "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  19.7s\n",
            "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=  20.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  21.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  20.8s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  21.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  21.4s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  21.2s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.6s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  18.9s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  19.1s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  20.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  19.7s\n",
            "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
            "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=  22.7s\n",
            "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=  23.2s\n",
            "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=  22.6s\n",
            "[CV] END .......................C=5, gamma=scale, kernel=rbf; total time=  21.8s\n",
            "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=  23.1s\n",
            "[CV] END .......................C=5, gamma=scale, kernel=rbf; total time=  20.9s\n",
            "[CV] END .......................C=5, gamma=scale, kernel=rbf; total time=  21.0s\n",
            "[CV] END .......................C=5, gamma=scale, kernel=rbf; total time=  20.9s\n",
            "[CV] END .......................C=5, gamma=scale, kernel=rbf; total time=  21.1s\n",
            "[CV] END ........................C=5, gamma=auto, kernel=rbf; total time=  20.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kunaljindal/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........................C=5, gamma=auto, kernel=rbf; total time=  20.6s\n",
            "[CV] END ........................C=5, gamma=auto, kernel=rbf; total time=  20.6s\n",
            "[CV] END ........................C=5, gamma=auto, kernel=rbf; total time=  21.0s\n",
            "[CV] END ........................C=5, gamma=auto, kernel=rbf; total time=  21.2s\n",
            "[CV] END ........................C=5, gamma=0.01, kernel=rbf; total time=  23.5s\n",
            "[CV] END ........................C=5, gamma=0.01, kernel=rbf; total time=  24.6s\n",
            "[CV] END ........................C=5, gamma=0.01, kernel=rbf; total time=  24.5s\n",
            "[CV] END .......................C=5, gamma=0.001, kernel=rbf; total time=  21.7s\n",
            "[CV] END ........................C=5, gamma=0.01, kernel=rbf; total time=  25.6s\n",
            "[CV] END ........................C=5, gamma=0.01, kernel=rbf; total time=  25.1s\n",
            "[CV] END .......................C=5, gamma=0.001, kernel=rbf; total time=  21.4s\n",
            "[CV] END .......................C=5, gamma=0.001, kernel=rbf; total time=  23.8s\n",
            "[CV] END .......................C=5, gamma=0.001, kernel=rbf; total time=  24.7s\n",
            "[CV] END .......................C=5, gamma=0.001, kernel=rbf; total time=  26.4s\n",
            "[CV] END ......................C=5, gamma=0.0001, kernel=rbf; total time=  27.3s\n",
            "[CV] END ......................C=5, gamma=0.0001, kernel=rbf; total time=  28.4s\n",
            "[CV] END ......................C=5, gamma=0.0001, kernel=rbf; total time=  27.1s\n",
            "[CV] END ......................C=5, gamma=0.0001, kernel=rbf; total time=  28.3s\n",
            "[CV] END ......................C=5, gamma=0.0001, kernel=rbf; total time=  27.6s\n",
            "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=  32.2s\n",
            "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=  32.6s\n",
            "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=  31.4s\n",
            "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=  32.2s\n",
            "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=  31.4s\n",
            "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  31.0s\n",
            "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  31.8s\n",
            "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  30.7s\n",
            "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  30.7s\n",
            "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  30.5s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  26.9s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  33.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  32.9s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  33.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  32.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  31.9s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  24.4s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  23.6s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  24.7s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=  24.5s\n",
            "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=  24.1s\n",
            "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=  24.2s\n",
            "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=  24.4s\n",
            "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=  24.0s\n",
            "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=  23.2s\n",
            "[CV] END ......................C=20, gamma=scale, kernel=rbf; total time=  27.5s\n",
            "[CV] END ......................C=20, gamma=scale, kernel=rbf; total time=  27.7s\n",
            "[CV] END ......................C=20, gamma=scale, kernel=rbf; total time=  27.6s\n",
            "[CV] END ......................C=20, gamma=scale, kernel=rbf; total time=  27.4s\n",
            "[CV] END ......................C=20, gamma=scale, kernel=rbf; total time=  27.5s\n",
            "[CV] END .......................C=20, gamma=auto, kernel=rbf; total time=  27.4s\n",
            "[CV] END .......................C=20, gamma=auto, kernel=rbf; total time=  27.3s\n",
            "[CV] END .......................C=20, gamma=auto, kernel=rbf; total time=  26.0s\n",
            "[CV] END .......................C=20, gamma=auto, kernel=rbf; total time=  26.4s\n",
            "[CV] END .......................C=20, gamma=auto, kernel=rbf; total time=  26.1s\n",
            "[CV] END .......................C=20, gamma=0.01, kernel=rbf; total time=  27.9s\n",
            "[CV] END .......................C=20, gamma=0.01, kernel=rbf; total time=  28.0s\n",
            "[CV] END .......................C=20, gamma=0.01, kernel=rbf; total time=  27.4s\n",
            "[CV] END .......................C=20, gamma=0.01, kernel=rbf; total time=  27.6s\n",
            "[CV] END .......................C=20, gamma=0.01, kernel=rbf; total time=  28.0s\n",
            "[CV] END ......................C=20, gamma=0.001, kernel=rbf; total time=  20.3s\n",
            "[CV] END ......................C=20, gamma=0.001, kernel=rbf; total time=  21.9s\n",
            "[CV] END ......................C=20, gamma=0.001, kernel=rbf; total time=  21.5s\n",
            "[CV] END ......................C=20, gamma=0.001, kernel=rbf; total time=  23.1s\n",
            "[CV] END ......................C=20, gamma=0.001, kernel=rbf; total time=  22.9s\n",
            "[CV] END .....................C=20, gamma=0.0001, kernel=rbf; total time=  22.6s\n",
            "[CV] END .....................C=20, gamma=0.0001, kernel=rbf; total time=  22.2s\n",
            "[CV] END .....................C=20, gamma=0.0001, kernel=rbf; total time=  22.4s\n",
            "[CV] END .....................C=20, gamma=0.0001, kernel=rbf; total time=  22.0s\n",
            "[CV] END .....................C=20, gamma=0.0001, kernel=rbf; total time=  14.5s\n",
            "\n",
            "Best Parameters from Grid Search:\n",
            "{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "\n",
            "Best CV Accuracy: 0.7370000452882284\n",
            "\n",
            "Training Accuracy: 0.787893156314209\n",
            "\n",
            "Classification Report (Training Data):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.89      0.86      6245\n",
            "         1.0       0.72      0.79      0.75      4945\n",
            "         2.0       0.82      0.35      0.49      1464\n",
            "\n",
            "    accuracy                           0.79     12654\n",
            "   macro avg       0.79      0.68      0.70     12654\n",
            "weighted avg       0.79      0.79      0.78     12654\n",
            "\n",
            "svm_gridsearch.csv created!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Define parameter grid\n",
        "# -------------------------\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 5, 10, 20],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.001, 0.0001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Grid Search with 5-fold CV\n",
        "# -------------------------\n",
        "grid = GridSearchCV(\n",
        "    estimator=SVC(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"\\nBest Parameters from Grid Search:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(\"\\nBest CV Accuracy:\", grid.best_score_)\n",
        "\n",
        "# -------------------------\n",
        "# Train best model\n",
        "# -------------------------\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# -------------------------\n",
        "# Evaluate on training data\n",
        "# -------------------------\n",
        "train_pred = best_model.predict(X_scaled)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report (Training Data):\\n\")\n",
        "print(classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = best_model.predict(test_scaled)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission file\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    'trip_id': testId,\n",
        "    'spend_category': test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"svm_gridsearch.csv\", index=False)\n",
        "print(\"svm_gridsearch.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcncnzWQV9CV"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "R7uOYpotWG53",
        "outputId": "0f2a3b15-b8cc-42d9-f02d-e61947d91244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     16\u001b[39m rf = RandomForestClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     18\u001b[39m grid = GridSearchCV(\n\u001b[32m     19\u001b[39m     estimator=rf,\n\u001b[32m     20\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest Parameters:\u001b[39m\u001b[33m\"\u001b[39m, grid.best_params_)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV Score:\u001b[39m\u001b[33m\"\u001b[39m, grid.best_score_)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Grid search parameters\n",
        "# -------------------------\n",
        "param_grid = {\n",
        "    \"n_estimators\": [1000],\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Grid Search\n",
        "# -------------------------\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"\\nBest Parameters:\", grid.best_params_)\n",
        "print(\"Best CV Score:\", grid.best_score_)\n",
        "\n",
        "model = grid.best_estimator_\n",
        "\n",
        "# -------------------------\n",
        "# Training performance\n",
        "# -------------------------\n",
        "train_pred = model.predict(X_scaled)\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report (Training Data):\\n\")\n",
        "print(classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = model.predict(test_scaled)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission file\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"trip_id\": testId,\n",
        "    \"spend_category\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"randomForest_gridsearch.csv\", index=False)\n",
        "print(\"randomForest_gridsearch.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3LEbeJWDs5"
      },
      "source": [
        "Neural Ntwk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9onctaTLWHbe",
        "outputId": "5d06c0d8-65f7-4c91-864e-181cb9247829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "New Best Score: 0.9769157544026654\n",
            "Params: {'hidden_layer_sizes': (128, 512, 1024), 'activation': 'relu', 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
            "--------------------------------------------------\n",
            "\n",
            "Final Best Training Accuracy: 0.9769157544026654\n",
            "Best Params: {'hidden_layer_sizes': (128, 512, 1024), 'activation': 'relu', 'solver': 'adam', 'learning_rate_init': 0.001, 'alpha': 0.0001}\n",
            "pytorch_mlp_gpu_gridsearch.csv created!\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# -------------------------\n",
        "# Device (GPU if available)\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# Convert numpy â†’ tensors\n",
        "# -------------------------\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
        "test_tensor = torch.tensor(test_scaled, dtype=torch.float32)\n",
        "\n",
        "# Dataloaders (mini-batch)\n",
        "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# -------------------------\n",
        "# Define MLP model\n",
        "# -------------------------\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_layers, activation_fn, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(activation_fn())\n",
        "            prev = h\n",
        "\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# -------------------------\n",
        "# Activation mapping\n",
        "# -------------------------\n",
        "activation_map = {\n",
        "    \"relu\": nn.ReLU,\n",
        "    \"tanh\": nn.Tanh,\n",
        "    \"logistic\": nn.Sigmoid\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Hyperparameter grid\n",
        "# -------------------------\n",
        "# param_grid = {\n",
        "#     \"hidden_layer_sizes\": [(64, 32), (128, 64)],\n",
        "#     \"activation\": [\"relu\"],\n",
        "#     \"solver\": [\"adam\", \"sgd\"],\n",
        "#     \"learning_rate_init\": [0.001, 0.01],\n",
        "#     \"alpha\": [0.0001, 0.0005],\n",
        "# }\n",
        "param_grid = {'hidden_layer_sizes': [(128, 512, 1024)], 'activation': ['relu'], 'solver': ['adam'], 'learning_rate_init': [0.001], 'alpha': [0.0001]}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Training function (GPU)\n",
        "# -------------------------\n",
        "def train_model(model, optimizer, criterion, early_stopping=True, patience=20):\n",
        "    model.train()\n",
        "    best_loss = np.inf\n",
        "    best_state = None\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(200):   # fewer epochs required because GPU + mini-batch\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Early stopping check\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        if early_stopping:\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                best_state = model.state_dict()\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "\n",
        "            if no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    if early_stopping and best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return best_loss\n",
        "\n",
        "# -------------------------\n",
        "# Manual Grid Search (GPU)\n",
        "# -------------------------\n",
        "best_score = -1\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "input_dim = X_scaled.shape[1]\n",
        "output_dim = len(np.unique(y))\n",
        "\n",
        "for hidden in param_grid[\"hidden_layer_sizes\"]:\n",
        "    for activation in param_grid[\"activation\"]:\n",
        "        for solver in param_grid[\"solver\"]:\n",
        "            for lr in param_grid[\"learning_rate_init\"]:\n",
        "                for wd in param_grid[\"alpha\"]:\n",
        "\n",
        "                    act_fn = activation_map[activation]\n",
        "\n",
        "                    model = MLP(hidden, act_fn, input_dim, output_dim).to(device)\n",
        "\n",
        "                    if solver == \"adam\":\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "                    else:\n",
        "                        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "                    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "                    train_model(model, optimizer, criterion, early_stopping=True)\n",
        "\n",
        "                    # Evaluate on full training set\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        preds = torch.argmax(model(X_tensor.to(device)), dim=1).cpu().numpy()\n",
        "                        acc = accuracy_score(y, preds)\n",
        "\n",
        "                    if acc > best_score:\n",
        "                        best_score = acc\n",
        "                        best_params = {\n",
        "                            \"hidden_layer_sizes\": hidden,\n",
        "                            \"activation\": activation,\n",
        "                            \"solver\": solver,\n",
        "                            \"learning_rate_init\": lr,\n",
        "                            \"alpha\": wd\n",
        "                        }\n",
        "                        best_model = model\n",
        "\n",
        "                        print(\"\\nNew Best Score:\", best_score)\n",
        "                        print(\"Params:\", best_params)\n",
        "                        print(\"-\" * 50)\n",
        "\n",
        "# -------------------------\n",
        "# Final training accuracy\n",
        "# -------------------------\n",
        "print(\"\\nFinal Best Training Accuracy:\", best_score)\n",
        "print(\"Best Params:\", best_params)\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_pred = torch.argmax(best_model(test_tensor.to(device)), dim=1).cpu().numpy()\n",
        "\n",
        "# -------------------------\n",
        "# Create submission\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"trip_id\": testId,\n",
        "    \"spend_category\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"pytorch_mlp_gpu_gridsearch.csv\", index=False)\n",
        "print(\"pytorch_mlp_gpu_gridsearch.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "nn with bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Training model 1/30 ...\n",
            "Training model 2/30 ...\n",
            "Training model 3/30 ...\n",
            "Training model 4/30 ...\n",
            "Training model 5/30 ...\n",
            "Training model 6/30 ...\n",
            "Training model 7/30 ...\n",
            "Training model 8/30 ...\n",
            "Training model 9/30 ...\n",
            "Training model 10/30 ...\n",
            "Training model 11/30 ...\n",
            "Training model 12/30 ...\n",
            "Training model 13/30 ...\n",
            "Training model 14/30 ...\n",
            "Training model 15/30 ...\n",
            "Training model 16/30 ...\n",
            "Training model 17/30 ...\n",
            "Training model 18/30 ...\n",
            "Training model 19/30 ...\n",
            "Training model 20/30 ...\n",
            "Training model 21/30 ...\n",
            "Training model 22/30 ...\n",
            "Training model 23/30 ...\n",
            "Training model 24/30 ...\n",
            "Training model 25/30 ...\n",
            "Training model 26/30 ...\n",
            "Training model 27/30 ...\n",
            "Training model 28/30 ...\n",
            "Training model 29/30 ...\n",
            "Training model 30/30 ...\n",
            "\n",
            "Training Accuracy: 0.9066317626527051\n",
            "pytorch_bagging_nn.csv created!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "\n",
        "# -------------------------\n",
        "# Device\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# Convert numpy â†’ tensors\n",
        "# -------------------------\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
        "test_tensor = torch.tensor(test_scaled, dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "# -------------------------\n",
        "# Base MLP Model\n",
        "# -------------------------\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_layers, activation_fn, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(activation_fn())\n",
        "            prev = h\n",
        "\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# -------------------------\n",
        "# Training function for each NN\n",
        "# -------------------------\n",
        "def train_single_model(model, loader, lr=0.001, wd=1e-4, epochs=40):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "# -------------------------\n",
        "# Bagging Ensemble\n",
        "# -------------------------\n",
        "def bagging_ensemble(\n",
        "    n_estimators=20,\n",
        "    sample_ratio=0.6,\n",
        "    batch_size=256,\n",
        "    hidden=(128, 64),\n",
        "    activation=\"relu\",\n",
        "    lr=0.001,\n",
        "    weight_decay=0.0001,\n",
        "):\n",
        "    activation_map = {\n",
        "        \"relu\": nn.ReLU,\n",
        "        \"tanh\": nn.Tanh,\n",
        "        \"logistic\": nn.Sigmoid\n",
        "    }\n",
        "\n",
        "    act_fn = activation_map[activation]\n",
        "\n",
        "    models = []\n",
        "    input_dim = X_tensor.shape[1]\n",
        "    output_dim = len(np.unique(y_tensor.numpy()))\n",
        "\n",
        "    N = len(train_dataset)\n",
        "    sample_size = int(sample_ratio * N)\n",
        "\n",
        "    for i in range(n_estimators):\n",
        "        # Bootstrap sample\n",
        "        indices = np.random.choice(N, size=sample_size, replace=True)\n",
        "        bootstrap_ds = Subset(train_dataset, indices)\n",
        "        loader = DataLoader(bootstrap_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Create model\n",
        "        model = MLP(hidden, act_fn, input_dim, output_dim).to(device)\n",
        "\n",
        "        print(f\"Training model {i+1}/{n_estimators} ...\")\n",
        "        train_single_model(model, loader, lr, weight_decay)\n",
        "        models.append(model)\n",
        "\n",
        "    return models\n",
        "\n",
        "# -------------------------\n",
        "# Voting prediction\n",
        "# -------------------------\n",
        "def predict_ensemble(models, X):\n",
        "    preds = []\n",
        "    X = X.to(device)\n",
        "\n",
        "    for m in models:\n",
        "        m.eval()\n",
        "        with torch.no_grad():\n",
        "            p = torch.argmax(m(X), dim=1).cpu().numpy()\n",
        "            preds.append(p)\n",
        "\n",
        "    preds = np.array(preds)   # shape: (n_estimators, n_samples)\n",
        "    final_pred = []\n",
        "\n",
        "    for j in range(preds.shape[1]):\n",
        "        label = Counter(preds[:, j]).most_common(1)[0][0]\n",
        "        final_pred.append(label)\n",
        "\n",
        "    return np.array(final_pred)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Train the Bagging Ensemble\n",
        "# ----------------------------------------------------\n",
        "models = bagging_ensemble(\n",
        "    n_estimators=30,\n",
        "    hidden=(512, 1024, 128),\n",
        "    activation=\"relu\",\n",
        "    sample_ratio=0.6,\n",
        "    batch_size=256,\n",
        "    lr=0.001,\n",
        "    weight_decay=0.0001\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Training accuracy\n",
        "# -------------------------\n",
        "train_pred = predict_ensemble(models, X_tensor)\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = predict_ensemble(models, test_tensor)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"trip_id\": testId,\n",
        "    \"spend_category\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"pytorch_bagging_nn.csv\", index=False)\n",
        "print(\"pytorch_bagging_nn.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx61-uWw99bJ"
      },
      "source": [
        "CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQXA-1nU9-kl",
        "outputId": "9887043e-e1be-4cef-9421-7248b5b47040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.7911332385016595\n",
            "\n",
            "Classification Report (Training Data):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.88      0.86      6245\n",
            "         1.0       0.72      0.79      0.75      4945\n",
            "         2.0       0.79      0.44      0.56      1464\n",
            "\n",
            "    accuracy                           0.79     12654\n",
            "   macro avg       0.79      0.70      0.73     12654\n",
            "weighted avg       0.79      0.79      0.79     12654\n",
            "\n",
            "catboost.csv created!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Train the model\n",
        "# -------------------------\n",
        "model = CatBoostClassifier(\n",
        "    iterations=500,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    loss_function='MultiClass',\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# -------------------------\n",
        "# Evaluate on training data\n",
        "# -------------------------\n",
        "train_pred = model.predict(X_scaled)\n",
        "train_pred = train_pred.reshape(-1)  # flatten predictions\n",
        "\n",
        "print(\"Training Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report (Training Data):\\n\")\n",
        "print(classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = model.predict(test_scaled)\n",
        "test_pred = test_pred.reshape(-1)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission file\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    'trip_id': testId,\n",
        "    'spend_category': test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"catboost1.csv\", index=False)\n",
        "print(\"catboost.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "K nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=3, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=uniform; total time=   0.8s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=5, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=7, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=9, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=uniform; total time=   0.8s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=uniform; total time=   0.8s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=1, weights=distance; total time=   0.7s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=euclidean, n_neighbors=21, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=distance; total time=   3.0s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=3, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=5, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=uniform; total time=   3.0s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=7, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=distance; total time=   3.0s\n",
            "[CV] END metric=manhattan, n_neighbors=9, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=11, p=2, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=15, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=uniform; total time=   3.0s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=manhattan, n_neighbors=21, p=2, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=uniform; total time=   3.0s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=distance; total time=   3.1s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=uniform; total time=   0.8s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=5, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=uniform; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=distance; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=uniform; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=distance; total time=   3.2s\n",
            "[CV] END metric=minkowski, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=uniform; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=uniform; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=uniform; total time=   3.7s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=uniform; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=uniform; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=distance; total time=   3.8s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=distance; total time=   3.8s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=distance; total time=   3.9s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=9, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=   3.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=distance; total time=   3.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=distance; total time=   3.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=distance; total time=   3.7s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=distance; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=11, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=uniform; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=uniform; total time=   0.8s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=15, p=1, weights=distance; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=uniform; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=uniform; total time=   3.3s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=uniform; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=uniform; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=uniform; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=distance; total time=   0.7s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=distance; total time=   3.5s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=distance; total time=   3.4s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=distance; total time=   0.6s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=2, weights=distance; total time=   0.5s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=distance; total time=   2.8s\n",
            "[CV] END metric=minkowski, n_neighbors=21, p=1, weights=distance; total time=   2.7s\n",
            "\n",
            "Best Parameters from Grid Search:\n",
            "{'metric': 'manhattan', 'n_neighbors': 21, 'p': 1, 'weights': 'uniform'}\n",
            "\n",
            "Best CV Accuracy: 0.741583526328858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kunaljindal/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Accuracy: 0.5807649755018176\n",
            "\n",
            "Classification Report (Training Data):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.63      0.74      6245\n",
            "         1.0       0.52      0.46      0.49      4945\n",
            "         2.0       0.29      0.75      0.42      1464\n",
            "\n",
            "    accuracy                           0.58     12654\n",
            "   macro avg       0.57      0.62      0.55     12654\n",
            "weighted avg       0.68      0.58      0.61     12654\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kunaljindal/Desktop/Machine Learning/Project/Travel_Behaviour/travel-behavior-insights/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knn_gridsearch.csv created!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Define parameter grid\n",
        "# -------------------------\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 15, 21],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
        "    'p': [1, 2]   # p=1â†’Manhattan, p=2â†’Euclidean\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Grid Search with 5-fold CV\n",
        "# -------------------------\n",
        "grid = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"\\nBest Parameters from Grid Search:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(\"\\nBest CV Accuracy:\", grid.best_score_)\n",
        "\n",
        "# -------------------------\n",
        "# Train best model\n",
        "# -------------------------\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# -------------------------\n",
        "# Evaluate on training data\n",
        "# -------------------------\n",
        "train_pred = best_model.predict(X_scaled)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report (Training Data):\\n\")\n",
        "print(classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = best_model.predict(test_scaled)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission file\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    'trip_id': testId,\n",
        "    'spend_category': test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"knn_gridsearch.csv\", index=False)\n",
        "print(\"knn_gridsearch.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-10; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-10; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-10; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-10; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-10; total time=   0.0s\n",
            "\n",
            "Best Parameters from Grid Search:\n",
            "{'var_smoothing': 1e-06}\n",
            "\n",
            "Best CV Accuracy: 0.16073947868564192\n",
            "\n",
            "Training Accuracy: 0.16840524735261578\n",
            "\n",
            "Classification Report (Training Data):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.08      0.15      6245\n",
            "         1.0       0.70      0.03      0.06      4945\n",
            "         2.0       0.12      0.99      0.22      1464\n",
            "\n",
            "    accuracy                           0.17     12654\n",
            "   macro avg       0.52      0.37      0.14     12654\n",
            "weighted avg       0.66      0.17      0.12     12654\n",
            "\n",
            "bayes_gridsearch.csv created!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------\n",
        "# Parameter grid for GaussianNB\n",
        "# -------------------------\n",
        "param_grid = {\n",
        "    \"var_smoothing\": [1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Grid Search with 5-fold CV\n",
        "# -------------------------\n",
        "grid = GridSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"\\nBest Parameters from Grid Search:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(\"\\nBest CV Accuracy:\", grid.best_score_)\n",
        "\n",
        "# -------------------------\n",
        "# Train best model\n",
        "# -------------------------\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# -------------------------\n",
        "# Evaluate on training data\n",
        "# -------------------------\n",
        "train_pred = best_model.predict(X_scaled)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y, train_pred))\n",
        "print(\"\\nClassification Report (Training Data):\\n\")\n",
        "print(classification_report(y, train_pred))\n",
        "\n",
        "# -------------------------\n",
        "# Predict test data\n",
        "# -------------------------\n",
        "test_pred = best_model.predict(test_scaled)\n",
        "\n",
        "# -------------------------\n",
        "# Create submission file\n",
        "# -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"trip_id\": testId,\n",
        "    \"spend_category\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"bayes_gridsearch.csv\", index=False)\n",
        "print(\"bayes_gridsearch.csv created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='spend_category', ylabel='Count'>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "sns.histplot(df['spend_category'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
